<img src="https://github.com/Hgp-GeniusLabs/Curriculum/blob/10734f2c827128dde773ea4f266d154d46977866/Org-Wide/Assets/hgp_logo_original.png" width="150"/>

# LESSON 5: Classification in AI

## Overview			
* Understand the basics of AI
* See how AI shapes our future
* Learn how to maneuver around the world of AI
* Learn different components that make up AI
* Work with real world AI Applications

## Learning Activities and Time Duration(2 hours) 


1. **Welcome and Introduction (5 minutes):**
   - Briefly introduce yourself and set the context for the lesson. (Classification and Data Collection)

2. **Group Discussion (15 minutes):**
   - Ask students what they know about AI. Write their ideas on the whiteboard if available.
   - Define AI with a simple explanation and examples (e.g., personal assistants like Siri, recommendation systems like Netflix, self-driving cars).
   - Show a short, engaging video about AI ([AI Playing Games: Crash Course AI #12](https://www.youtube.com/watch?v=nw7zmdBLQ6U&list=PL8dPuuaLjXtO65LeD2p4_Sb5XQ51par_b&index=13)).

3. Play 3 rounds of Quick,Draw(https://quickdraw.withgoogle.com/) See who can get the AI to guess all 6

4. Discuss the Data that AI gets and have kids look at all the data drawings that Quick Draw has collected.

5. Take break (10 minutes)

Scratch Lab is a site where you can engage with experimental blocks, like Face Sensing. With
Face Sensing, create projects that respond to your eyes, nose, and other parts of your face.

1. To begin, navigate to https://lab.scratch.mit.edu/face.

2. Click the “Try it out” button at the top of the page.

3. A new project loads using the default Scratch Cat sprite. Just as in the Scratch editor,
users can use this default sprite or choose another from the sprite library.

4. Face Sensing blocks use the device’s camera. If you haven’t enabled the camera in your browser for the Scratch Lab site, you may be prompted to give permission. How do Face Sensing blocks work? The AI we are using was trained on millions of photos of
people’s faces, called a data set. It detects things based on what it has already seen, like parts of a face and how they are arranged. The machine learning model looks for patterns like: a nose is between the eyes and mouth, eyes are typically a certain size in relation to the face, mouths may show teeth or not, etc. It can detect that a face exists, but cannot identify the person.

Experiment 1: Let’s try out the Face Sensing blocks!

1. Select the “go to nose” block and place it on the script area.

2. Click the block while your face is visible on the stage and see what happens. Did the
sprite go to your nose? Try moving and clicking the block again.

3. How can you make it constantly follow your nose? Encourage
them to find a block to help. Try selecting a forever loop from
the Control category and place the “go to nose” block inside it.

4. Select the Events category and add a “when green flag
clicked” block to the top of the code stack.

5. Click the green flag to see how this works. Did the sprite stick
to your nose and follow it around as you moved? What
happens if you click on the dropdown list and choose another
feature for the sprite to go to?

6. What happens if you add an additional block like “turn clockwise
15 degrees” from the Motion category? What if you choose “go
to left ear” from the dropdown menu in the “go to nose” block?

Experiment 2: Let’s draw a hat to stick to our head, like a face filter.

1. In the costume Paint Editor, try drawing a hat using brush or shape tools.

2. Add code, or adjust the code you already have, so it
sticks to the top of your head.

3. Is the placement of the object just right on your
face? Experiment with the placement on the
costume in the Paint Editor. For instance, can you
see the difference if a hat costume is centered
versus when only one edge is on the centerpoint?

4. Add another sprite from the sprite menu or draw another sprite and stick it to your ear, or
between your eyes… What else can you try?

5. Have you created multiple hat costumes? Add code to switch costumes.

Take time to make some observations while you experiment:
● How does the object appear on your face when you are close to the camera? What
happens if you are further from the camera? Do you see any blocks you could use so it
scales to match the size of your face?
● Does the object match the direction of your face tilt? Do you see blocks to match it?
